{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'nnutils' from '/home/jacobpri/git/RotspaceIT/notebooks/nnutils.py'>"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import os\n",
    "from os.path import join, exists\n",
    "import sys\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import torchvision.datasets as datasets\n",
    "from torch.autograd import Variable as V\n",
    "from torch.nn import functional as F\n",
    "import torch.nn  as nn\n",
    "from PIL import Image\n",
    "from IPython.core.debugger import set_trace\n",
    "import nethook as nethook\n",
    "import scipy.io as sio\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import importlib\n",
    "\n",
    "import nnutils as utils\n",
    "\n",
    "importlib.reload(utils)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "arch = 'resnet18'\n",
    "trained_on = 'object'\n",
    "imageset = 'mc8-lummatched'\n",
    "\n",
    "load_arch = arch + '-' + trained_on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## directory management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imageset dir /home/jacobpri/git/RotspaceIT/imagesets/experimental/mc8-lummatched\n",
      "weight dir /home/jacobpri/git/RotspaceIT/data/d02_modeling/weights\n",
      "activation save destination: /home/jacobpri/git/RotspaceIT/data/d02_modeling/activations/resnet18-object/experimental/mc8-lummatched\n"
     ]
    }
   ],
   "source": [
    "home_dir = '/home/jacobpri/git/RotspaceIT/'\n",
    "\n",
    "# target directory for saving activations\n",
    "activation_savedir = join(home_dir,'data','d02_modeling','activations')\n",
    "\n",
    "# folder of trained model weights\n",
    "weight_dir = join(home_dir,'data','d02_modeling','weights')\n",
    "\n",
    "# folder of image sets\n",
    "imageset_dir = join(home_dir,'imagesets')\n",
    "\n",
    "dirs = os.listdir(imageset_dir)\n",
    "\n",
    "found = False\n",
    "for d in dirs:\n",
    "    d_ = os.listdir(join(imageset_dir,d))\n",
    "    if (imageset in d_):\n",
    "        imageset_dir = join(imageset_dir, d, imageset)\n",
    "        activation_savedir = join(activation_savedir, load_arch, d, imageset)\n",
    "        found = True\n",
    "        break\n",
    "\n",
    "if found is False:\n",
    "    raise ValueError('image set not found')   \n",
    "\n",
    "# create savedir if it doesn't yet exist \n",
    "os.makedirs(activation_savedir, exist_ok=True)\n",
    "print(\"imageset dir %s\" % imageset_dir)\n",
    "print(\"weight dir %s\" % weight_dir)\n",
    "print(\"activation save destination: %s\" % activation_savedir)\n",
    "\n",
    "assert(exists(activation_savedir))\n",
    "assert(exists(imageset_dir))\n",
    "assert(exists(weight_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "if load_arch == 'alexnet':\n",
    "    model = models.alexnet(pretrained = True)\n",
    "elif load_arch == 'alexnet-random':\n",
    "    model = models.alexnet()\n",
    "elif load_arch == 'alexnet-object':\n",
    "    checkpoint = torch.load(os.path.join(weight_dir,'alexnet_imagenet_final.pth.tar'),map_location='cpu')\n",
    "    checkpoint['state_dict'] = {str.replace(k,'module.',''): v for k,v in checkpoint['state_dict'].items()}\n",
    "    model = models.alexnet(num_classes=1000)\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "elif load_arch == 'alexnet-face':\n",
    "    #model = models.__dict__['alexnet'](num_classes=9131)\n",
    "    checkpoint = torch.load(os.path.join(weight_dir,'alexnet_faces_final.pth.tar'),map_location='cpu')\n",
    "    #print(checkpoint['state_dict'].keys())\n",
    "    checkpoint['state_dict'] = {str.replace(k,'module.',''): v for k,v in checkpoint['state_dict'].items()}\n",
    "    model = models.alexnet(num_classes=3372)\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "elif load_arch == 'alexnet-scene':\n",
    "    checkpoint = torch.load(os.path.join(weight_dir,'alexnet_places_final.pth.tar'),map_location='cpu')\n",
    "    checkpoint['state_dict'] = {str.replace(k,'module.',''): v for k,v in checkpoint['state_dict'].items()}\n",
    "    model = models.alexnet(num_classes=365)\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "elif load_arch == 'resnet18-object':\n",
    "    model = models.resnet18(pretrained = True)\n",
    "elif load_arch == 'vgg16-object':\n",
    "    model = models.vgg16(pretrained = True)\n",
    "else:\n",
    "    raise ValueError('model name not recognized')\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get string names/indices of each layer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1_conv1', '2_norm1', '3_relu1', '4_maxpool1', '5_conv2', '6_norm2', '7_relu2', '8_conv3', '9_norm3', '10_conv4', '11_norm4', '12_relu4', '13_conv5', '14_norm5', '15_conv6', '16_norm6', '17_relu6', '18_conv7', '19_norm7', '20_downsample7', '21_norm7', '22_conv8', '23_norm8', '24_relu8', '25_conv9', '26_norm9', '27_conv10', '28_norm10', '29_relu10', '30_conv11', '31_norm11', '32_downsample11', '33_norm11', '34_conv12', '35_norm12', '36_relu12', '37_conv13', '38_norm13', '39_conv14', '40_norm14', '41_relu14', '42_conv15', '43_norm15', '44_downsample15', '45_norm15', '46_conv16', '47_norm16', '48_relu16', '49_conv17', '50_norm17', '51_avgpool17', '52_fc18']\n"
     ]
    }
   ],
   "source": [
    "lay_names_torch, lay_names_user, lay_names_user_fmt = utils.get_layer_names(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## convert model to instrumented model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you only want to do this conversion ONCE\n",
    "if not isinstance(model, nethook.InstrumentedModel):\n",
    "\n",
    "    # convert to instrumented model\n",
    "    model = nethook.InstrumentedModel(model)\n",
    "else:\n",
    "    print('warning: network is already InstrumentedModel')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## choose layers to retain (for extracting activations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['conv1', 'relu', 'layer1.0.conv1', 'layer1.0.relu', 'layer1.0.conv2', 'layer1.1.conv1', 'layer1.1.relu', 'layer1.1.conv2', 'layer2.0.conv1', 'layer2.0.relu', 'layer2.0.conv2', 'layer2.1.conv1', 'layer2.1.relu', 'layer2.1.conv2', 'layer3.0.conv1', 'layer3.0.relu', 'layer3.0.conv2', 'layer3.1.conv1', 'layer3.1.relu', 'layer3.1.conv2', 'layer4.0.conv1', 'layer4.0.relu', 'layer4.0.conv2', 'layer4.1.conv1', 'layer4.1.relu', 'layer4.1.conv2', 'fc'] \n",
      "\n",
      "['1_conv1', '3_relu1', '5_conv2', '7_relu2', '8_conv3', '10_conv4', '12_relu4', '13_conv5', '15_conv6', '17_relu6', '18_conv7', '22_conv8', '24_relu8', '25_conv9', '27_conv10', '29_relu10', '30_conv11', '34_conv12', '36_relu12', '37_conv13', '39_conv14', '41_relu14', '42_conv15', '46_conv16', '48_relu16', '49_conv17', '52_fc18'] \n",
      "\n",
      "27 layers chosen\n"
     ]
    }
   ],
   "source": [
    "all_types = ['conv','relu','pool','norm','drop','fc','downsample']\n",
    "includes = ['conv','relu','fc']#all_types#['conv','fc']\n",
    "\n",
    "layers_to_retain = []\n",
    "layers_to_retain_fmt = []\n",
    "\n",
    "for i in range(len(lay_names_user_fmt)):\n",
    "    if any(s in lay_names_user_fmt[i] for s in includes):\n",
    "        layers_to_retain.append(lay_names_torch[i])\n",
    "        layers_to_retain_fmt.append(lay_names_user_fmt[i])\n",
    "\n",
    "print(layers_to_retain,'\\n')\n",
    "print(layers_to_retain_fmt,'\\n')\n",
    "print('%d layers chosen' % len(layers_to_retain))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## retain chosen layers of instrumented model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer_name in layers_to_retain: model.retain_layer(layer_name) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = models.alexnet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('features', Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )),\n",
       " ('avgpool', AdaptiveAvgPool2d(output_size=(6, 6))),\n",
       " ('classifier', Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  ))]"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model2.named_children())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ = model2\n",
    "\n",
    "lay_names_torch = []\n",
    "lay_names_user = []\n",
    "lay_conv_strs = []\n",
    "layers = list(model_.named_modules())\n",
    "count = 0\n",
    "conv_count = 0\n",
    "\n",
    "for i in range(0,len(layers)):\n",
    "    #print(i)\n",
    "    module_type = layers[i][1].__class__.__name__\n",
    "    \n",
    "    nonbasic_types = np.array(['Sequential','BasicBlock','Bottleneck','Fire',\n",
    "                             '_DenseBlock', '_DenseLayer', 'Transition','InvertedResidual','_InvertedResidual','ConvBNReLU'])\n",
    "    \n",
    "    conv_types = ['conv','linear','fc']\n",
    "    conv_types = ['Conv','Linear']\n",
    "    \n",
    "    if np.logical_not(np.isin(module_type, nonbasic_types)):\n",
    "        \n",
    "        # get layer naming info\n",
    "        lay_names_torch.append(layers[i][0])\n",
    "        lay_names_user.append(str(count) + '_' + str(layers[i][1]).split('(')[0])\n",
    "\n",
    "        # get conv tag\n",
    "        if any(s in lay_names_user[-1] for s in conv_types) and 'downsample' not in lay_names_torch[-1]:\n",
    "            conv_count += 1\n",
    "        lay_conv_strs.append(str(conv_count))\n",
    "        \n",
    "        # update\n",
    "        lay_names_user[-1] = lay_names_user[-1] + '_' + lay_conv_strs[-1]\n",
    "\n",
    "        count += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', 'features.0', 'features.1', 'features.2', 'features.3', 'features.4', 'features.5', 'features.6', 'features.7', 'features.8', 'features.9', 'features.10', 'features.11', 'features.12', 'avgpool', 'classifier.0', 'classifier.1', 'classifier.2', 'classifier.3', 'classifier.4', 'classifier.5', 'classifier.6']\n"
     ]
    }
   ],
   "source": [
    "print(lay_names_torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('features.0', '1_Conv2d_1')\n",
      "('features.1', '2_ReLU_1')\n",
      "('features.2', '3_MaxPool2d_1')\n",
      "('features.3', '4_Conv2d_2')\n",
      "('features.4', '5_ReLU_2')\n",
      "('features.5', '6_MaxPool2d_2')\n",
      "('features.6', '7_Conv2d_3')\n",
      "('features.7', '8_ReLU_3')\n",
      "('features.8', '9_Conv2d_4')\n",
      "('features.9', '10_ReLU_4')\n",
      "('features.10', '11_Conv2d_5')\n",
      "('features.11', '12_ReLU_5')\n",
      "('features.12', '13_MaxPool2d_5')\n",
      "('avgpool', '14_AdaptiveAvgPool2d_5')\n",
      "('classifier.0', '15_Dropout_5')\n",
      "('classifier.1', '16_Linear_6')\n",
      "('classifier.2', '17_ReLU_6')\n",
      "('classifier.3', '18_Dropout_6')\n",
      "('classifier.4', '19_Linear_7')\n",
      "('classifier.5', '20_ReLU_7')\n",
      "('classifier.6', '21_Linear_8')\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,len(lay_names_torch)):\n",
    "    #num_idx[i][0] += 1\n",
    "    print((lay_names_torch[i],lay_names_user[i]))#,lay_conv_strs[i]))\n",
    "\n",
    "#print(lay_types)\n",
    "#print(len(lay_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_layer_names(model):\n",
    "    \n",
    "    lay_names_torch = []\n",
    "    lay_names_user = []\n",
    "    lay_conv_strs = []\n",
    "    \n",
    "    layers = list(model.named_modules())\n",
    "    \n",
    "    count = 1\n",
    "    conv_count = 0\n",
    "\n",
    "    for i in range(1,len(layers)):\n",
    "        \n",
    "        module_type = layers[i][1].__class__.__name__\n",
    "\n",
    "        nonbasic_types = np.array(['Sequential','BasicBlock','Bottleneck','Fire',\n",
    "                                 '_DenseBlock', '_DenseLayer', 'Transition', '_Transition','InvertedResidual','_InvertedResidual','ConvBNReLU'])\n",
    "\n",
    "        conv_types = ['Conv','Linear']\n",
    "\n",
    "        if np.logical_not(np.isin(module_type, nonbasic_types)):\n",
    "\n",
    "            # get layer naming info\n",
    "            lay_names_torch.append(layers[i][0])\n",
    "            lay_names_user.append(str(count) + '_' + str(layers[i][1]).split('(')[0])\n",
    "\n",
    "            # get conv tag\n",
    "            if any(s in lay_names_user[-1] for s in conv_types) and 'downsample' not in lay_names_torch[-1]:\n",
    "                conv_count += 1\n",
    "            lay_conv_strs.append(str(conv_count))\n",
    "\n",
    "            # update\n",
    "            lay_names_user[-1] = lay_names_user[-1] + '_' + lay_conv_strs[-1]\n",
    "\n",
    "            count += 1\n",
    "    \n",
    "    lay_names_user_fmt = []\n",
    "    \n",
    "    for lay in lay_names_user:\n",
    "        lay_type = lay.split('_')[1]\n",
    "        \n",
    "        if 'Conv' in lay_type:\n",
    "            fmt = 'conv'\n",
    "        elif 'Norm' in lay_type:\n",
    "            fmt = 'norm'\n",
    "        elif 'ReLU' in lay_type:\n",
    "            fmt = 'relu'\n",
    "        elif 'MaxPool' in lay_type:\n",
    "            fmt = 'maxpool'\n",
    "        elif 'AvgPool' in lay_type:\n",
    "            fmt = 'avgpool'\n",
    "        elif 'Linear' in lay_type:\n",
    "            fmt = 'fc'\n",
    "        elif 'Dropout' in lay_type:\n",
    "            fmt = 'drop'\n",
    "        else:\n",
    "            print(lay_type)\n",
    "            raise ValueError('fmt not implemented yet')\n",
    "        \n",
    "        lay_names_user_fmt.append(lay.split('_')[0] + '_' + fmt + lay.split('_')[2])\n",
    "\n",
    "    return lay_names_torch, lay_names_user, lay_names_user_fmt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-301-2594f81a5863>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_layer_strs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minception_v3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Gating/myenv/lib/python3.6/site-packages/torchvision/models/inception.py\u001b[0m in \u001b[0;36minception_v3\u001b[0;34m(pretrained, progress, **kwargs)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mInception3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Gating/myenv/lib/python3.6/site-packages/torchvision/models/inception.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, num_classes, aux_logits, transform_input)\u001b[0m\n\u001b[1;32m     84\u001b[0m                 \u001b[0mstddev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstddev\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'stddev'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtruncnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstddev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrvs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Gating/myenv/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py\u001b[0m in \u001b[0;36mrvs\u001b[0;34m(self, size, random_state)\u001b[0m\n\u001b[1;32m    461\u001b[0m         \u001b[0mkwds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'random_state'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrvs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Gating/myenv/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py\u001b[0m in \u001b[0;36mrvs\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    978\u001b[0m         \u001b[0;31m# by _rvs().\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 980\u001b[0;31m         \u001b[0mvals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rvs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    981\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    982\u001b[0m         \u001b[0mvals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvals\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mscale\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Gating/myenv/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py\u001b[0m in \u001b[0;36m_rvs\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    911\u001b[0m         \u001b[0;31m## Use basic inverse cdf algorithm for RV generation as default.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m         \u001b[0mU\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_random_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 913\u001b[0;31m         \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ppf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    914\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Gating/myenv/lib/python3.6/site-packages/scipy/stats/_continuous_distns.py\u001b[0m in \u001b[0;36m_ppf\u001b[0;34m(self, q, a, b)\u001b[0m\n\u001b[1;32m   7161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7162\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_ppf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7163\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_truncnorm_ppf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7165\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_munp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Gating/myenv/lib/python3.6/site-packages/scipy/stats/_continuous_distns.py\u001b[0m in \u001b[0;36mvf_wrapper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   6931\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6932\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mvf_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6933\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mvf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6934\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mvf_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6935\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mvectorize_decorator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Gating/myenv/lib/python3.6/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2089\u001b[0m             \u001b[0mvargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_n\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_n\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2091\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_vectorize_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2092\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2093\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_ufunc_and_otypes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Gating/myenv/lib/python3.6/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36m_vectorize_call\u001b[0;34m(self, func, args)\u001b[0m\n\u001b[1;32m   2165\u001b[0m                       for a in args]\n\u001b[1;32m   2166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2167\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2169\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnout\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Gating/myenv/lib/python3.6/site-packages/scipy/stats/_continuous_distns.py\u001b[0m in \u001b[0;36m_truncnorm_ppf\u001b[0;34m(q, a, b)\u001b[0m\n\u001b[1;32m   7087\u001b[0m         \u001b[0mna\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_norm_cdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7088\u001b[0m         \u001b[0mnb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_norm_cdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7089\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_norm_ppf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnb\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mna\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7091\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misinf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Gating/myenv/lib/python3.6/site-packages/scipy/stats/_continuous_distns.py\u001b[0m in \u001b[0;36m_norm_ppf\u001b[0;34m(q)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_norm_ppf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndtri\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "get_layer_strs(models.inception_v3())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## convert to instrumented model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## retain all layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
